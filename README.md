# Arquitetura-VKFormer

Este reposit√≥rio apresenta abordagens de aten√ß√£o n√£o quadr√°tica, vetores alternativos aos embeddings tradicionais e uma nova arquitetura que tem potencial para superar modelos atuais em efici√™ncia e capacidade de contextualiza√ß√£o.

## Componentes principais

### üî∏ VKT-attention
Um mecanismo de aten√ß√£o escalar, n√£o quadr√°tico, que elimina a necessidade de produtos de QK^T. Ele calcula a import√¢ncia de cada token com base em um valor trein√°vel (`V`), um vetor de contexto (`K`) e o vetor atual (`Q`). Essa aten√ß√£o permite maior escalabilidade e foco din√¢mico sem multiplica√ß√µes cruzadas pesadas.

### üîπ TCS-V (Token Contextual Scalar Vector)
Uma alternativa aos embeddings tradicionais, baseada em vetores de 14 dimens√µes. Cada vetor incorpora:
- Categoria gramatical (ex: substantivo, verbo, etc.)
- Identificadores de contexto (tokens ao redor)
- Posi√ß√£o do token
Esses vetores s√£o gerados por uma rede leve baseada em opera√ß√µes ponderadas entre os IDs normalizados dos tokens.

---

## üìÇ Arquivos inclu√≠dos

- `VKT-attention.md` ‚Äì Explica√ß√£o t√©cnica do mecanismo de aten√ß√£o
- `TCS-V.md` ‚Äì Gera√ß√£o e estrutura dos vetores
- `VKFormer.md` ‚Äì Arquitetura geral que utiliza ambos os m√©todos
- `PGV-3B5.md` ‚Äì Exemplo de modelo com 3.5B de par√¢metros e 128k tokens de contexto
- `LICENSE` ‚Äì Licen√ßa MIT (uso livre com cr√©dito ao autor)

---

## ‚öôÔ∏è Licen√ßa

Distribu√≠do sob a licen√ßa MIT. Uso comercial e modifica√ß√µes s√£o permitidos, desde que o autor original seja creditado (com link para este reposit√≥rio ou men√ß√£o ao nome da conta do GitHub).

---

## ‚ú® Contribui√ß√µes

Sugest√µes, cr√≠ticas construtivas e melhorias s√£o bem-vindas. Voc√™ pode abrir uma _issue_ ou enviar um _pull request_.
